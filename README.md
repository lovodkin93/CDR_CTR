# <h2 align="center"> Don’t Add, don’t Miss: Effective Content Preserving Generation from Pre-Selected Text Spans </h2>

Repository for our EMNLP 2023 findings paper "[Don’t Add, don’t Miss: Effective Content Preserving Generation from Pre-Selected Text Spans](https://aclanthology.org/2023.findings-emnlp.852/)"

In this repository, we include our 3 techniques to improve the Controlled Text Reduction (CTR) task: {C}ontrolled decoding, {D}istillation from GPT-4 and {R}einforcement Learning (CDR).

Full Code coming soon...





You can download the weights of the best variant in:
[best model weights](https://drive.google.com/drive/folders/11k_BTiXD6ItjEhN4wp267HRjg1euttL7?usp=sharing)
